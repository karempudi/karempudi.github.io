---
layout: post
title: Learning CUDA, Triton, and related things
data: 2024-01-15 09:00:00
description: 
tage: ML code CUDA
categories: Programming
published: false
related_posts: false
---

By the end of this lecture series, I want to write a really fast spatial clustering algorithms with certain priors on the structure of the spatial domain. I will use this later on in my work.

Goals: I would be learning CUDA, Triton, pytorch internals and much more related to running modern ML/AI algorithms faster. I should be able to understand FlashAttention, MAMBA, tinygrad etc and all the new optimizations and interesting things people are doing these days.

This is just my notes all in one place. The original repo for the code from the CUDA-MODE lectures is [here](https://github.com/cuda-mode/lectures.git).

### [Lecture 1](https://www.youtube.com/watch?v=LuhJEEJQgUM)

#### Easiest way to 
Easiest way to run the get C++ functions access is to use `load_inline` function from `torch.utils.cpp_extension`. The code is simple, it generates a shared `.so` file. The functions are loaded and accessible in python. 

```c++
import torch
import time
from time import perf_counter
from torch.utils.cpp_extension import load_inline

start = perf_counter()

cpp_source = """
std::string hello_world() {
  return "Hello World!";
}
std::string hello_praneeth() {
  return "Hello Praneeth!";
}
"""

my_module = load_inline(
    name='my_module',
    cpp_sources=[cpp_source],
    functions=['hello_world', 'hello_praneeth'],
    verbose=False,
    build_directory='./tmp'
)
print(f"Time to compile and module: {perf_counter() - start}s")

start_functions = perf_counter()
print(my_module.hello_world())
print(my_module.hello_praneeth())
print(f"Time to run two functions: {perf_counter() - start_functions}")
```

The compilation for the first time took 11s, but reloading only took 6ms. This is nice for simple functions. It generates a .cpp file and defines a `PYBIND11_MODULE` with the functions defined as part of the module.


#### Profiling pytorch code.



### [Lecture 2]()

Reading Programming massively parallel programming Chapters 1,2,3 and doing exercises.



### [Lecture 3]()


### [Lecture 4]()


### [Lecture 5]()


